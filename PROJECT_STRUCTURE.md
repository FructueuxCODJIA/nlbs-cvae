# NLBS-CVAE - Arborescence ComplÃ¨te du Projet

## Vue d'ensemble
Projet de gÃ©nÃ©ration d'images mammographiques utilisant un Conditional Variational Autoencoder (CVAE) optimisÃ© pour l'entraÃ®nement sur HPC.

```
nlbs-cvae/
â”œâ”€â”€ ğŸ“ assessment/                    # Ã‰valuation et mÃ©triques
â”‚   â””â”€â”€ evaluate_model.py            # Script d'Ã©valuation des modÃ¨les
â”‚
â”œâ”€â”€ ğŸ“ configs/                      # Configurations d'entraÃ®nement
â”‚   â”œâ”€â”€ training_config.yaml         # Configuration locale standard
â”‚   â””â”€â”€ hpc_training_config.yaml     # Configuration optimisÃ©e HPC
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Gestion des donnÃ©es
â”‚   â”œâ”€â”€ __init__.py                  # Module data
â”‚   â”œâ”€â”€ dataset.py                   # Dataset NLBS mammographique
â”‚   â”œâ”€â”€ transforms.py                # Transformations d'images
â”‚   â””â”€â”€ utils.py                     # Utilitaires de donnÃ©es
â”‚
â”œâ”€â”€ ğŸ“ envs/                         # Environnements
â”‚   â””â”€â”€ requirements.yaml            # DÃ©pendances Conda
â”‚
â”œâ”€â”€ ğŸ“ models/                       # Architecture du modÃ¨le
â”‚   â”œâ”€â”€ __init__.py                  # Module models
â”‚   â”œâ”€â”€ cvae.py                      # Conditional VAE principal
â”‚   â”œâ”€â”€ layers.py                    # Couches personnalisÃ©es
â”‚   â””â”€â”€ losses.py                    # Fonctions de perte
â”‚
â”œâ”€â”€ ğŸ“ results/                      # RÃ©sultats d'entraÃ®nement
â”‚   â”œâ”€â”€ galleries/                   # Galeries d'images gÃ©nÃ©rÃ©es
â”‚   â””â”€â”€ logs/                        # Logs d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“ training/                     # Scripts d'entraÃ®nement
â”‚   â””â”€â”€ train_cvae.py                # Script principal d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“ utils/                        # Utilitaires gÃ©nÃ©raux
â”‚   â”œâ”€â”€ __init__.py                  # Module utils
â”‚   â”œâ”€â”€ generate_samples.py          # GÃ©nÃ©ration d'Ã©chantillons
â”‚   â””â”€â”€ training_utils.py            # Utilitaires d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“„ DOCUMENTATION/                # Documentation complÃ¨te
â”‚   â”œâ”€â”€ README.md                    # Documentation principale
â”‚   â”œâ”€â”€ NLBS_CVAE_Architecture_Guide.md  # Guide architecture
â”‚   â”œâ”€â”€ HPC_INSTALLATION_GUIDE.md   # Guide installation HPC
â”‚   â”œâ”€â”€ ASUKA_TRANSFER_GUIDE.md      # Guide transfert Asuka
â”‚   â”œâ”€â”€ ASUKA_QUICKSTART.md          # DÃ©marrage rapide Asuka
â”‚   â””â”€â”€ hpc_setup.md                 # Configuration HPC
â”‚
â”œâ”€â”€ ğŸ”§ SCRIPTS HPC/                  # Scripts de dÃ©ploiement HPC
â”‚   â”œâ”€â”€ setup_hpc.sh                # Installation HPC principale
â”‚   â”œâ”€â”€ setup_hpc_offline.sh        # Installation hors ligne
â”‚   â”œâ”€â”€ setup_asuka.sh               # Installation Asuka
â”‚   â”œâ”€â”€ setup_asuka_custom.sh        # Installation Asuka personnalisÃ©e
â”‚   â”œâ”€â”€ check_hpc_environment.sh     # VÃ©rification environnement
â”‚   â”œâ”€â”€ check_hpc_readiness.sh       # VÃ©rification prÃ©paration
â”‚   â”œâ”€â”€ transfer_to_hpc.sh           # Transfert vers HPC
â”‚   â”œâ”€â”€ transfer_to_asuka.sh         # Transfert vers Asuka
â”‚   â”œâ”€â”€ download_results.sh          # TÃ©lÃ©chargement rÃ©sultats
â”‚   â””â”€â”€ monitor_hpc.sh               # Monitoring HPC
â”‚
â”œâ”€â”€ âš™ï¸ SLURM JOBS/                   # Scripts de soumission
â”‚   â”œâ”€â”€ train_job.slurm              # Job SLURM standard
â”‚   â””â”€â”€ train_asuka.slurm            # Job SLURM Asuka
â”‚
â”œâ”€â”€ ğŸ§ª TESTS/                        # Scripts de test
â”‚   â”œâ”€â”€ demo.py                      # DÃ©monstration complÃ¨te
â”‚   â”œâ”€â”€ quick_train.py               # EntraÃ®nement rapide
â”‚   â”œâ”€â”€ test_model.py                # Test du modÃ¨le
â”‚   â”œâ”€â”€ test_dataset.py              # Test du dataset
â”‚   â”œâ”€â”€ test_structure.py            # Test de la structure
â”‚   â””â”€â”€ test_training.py             # Test d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“¦ REQUIREMENTS/                 # DÃ©pendances
â”‚   â”œâ”€â”€ requirements.txt             # DÃ©pendances standard
â”‚   â””â”€â”€ requirements_hpc.txt         # DÃ©pendances HPC
â”‚
â””â”€â”€ ğŸ“ .venv/                        # Environnement virtuel local
    â””â”€â”€ [environnement Python local]
```

## DÃ©tails des Composants

### ğŸ—ï¸ Architecture du ModÃ¨le (`models/`)

#### `cvae.py` - Conditional VAE Principal
- **ConditionalVAE**: Classe principale du modÃ¨le
- **Encoder**: RÃ©seau encodeur avec convolutions
- **Decoder**: RÃ©seau dÃ©codeur avec convolutions transposÃ©es
- **Conditioning**: Injection de conditions via FiLM
- **Reparameterization**: Trick de reparamÃ©trisation VAE

#### `layers.py` - Couches PersonnalisÃ©es
- **FiLMLayer**: Feature-wise Linear Modulation
- **ResidualBlock**: Blocs rÃ©siduels
- **AttentionBlock**: MÃ©canismes d'attention
- **GroupNorm**: Normalisation par groupes

#### `losses.py` - Fonctions de Perte
- **VAELoss**: Perte combinÃ©e reconstruction + KL
- **ReconstructionLoss**: Perte de reconstruction (MSE/L1)
- **KLDivergenceLoss**: Divergence KL avec annealing
- **EdgeLoss**: Perte de prÃ©servation des contours

### ğŸ“Š Gestion des DonnÃ©es (`data/`)

#### `dataset.py` - Dataset NLBS
- **NLBSDataset**: Dataset principal pour mammographies
- **Preprocessing**: Normalisation et redimensionnement
- **Filtering**: Filtrage par fraction de premier plan
- **Metadata**: Gestion des mÃ©tadonnÃ©es cliniques

#### `transforms.py` - Transformations
- **Augmentations**: Rotation, flip, contraste, bruit
- **Normalization**: Normalisation des intensitÃ©s
- **Resizing**: Redimensionnement adaptatif
- **Patching**: Extraction de patches

#### `utils.py` - Utilitaires de DonnÃ©es
- **Data loading**: Chargement efficace des donnÃ©es
- **Validation**: Validation des donnÃ©es
- **Statistics**: Calcul de statistiques

### ğŸ¯ EntraÃ®nement (`training/`)

#### `train_cvae.py` - Script Principal
- **Training loop**: Boucle d'entraÃ®nement complÃ¨te
- **Validation**: Ã‰valuation pÃ©riodique
- **Checkpointing**: Sauvegarde des modÃ¨les
- **Logging**: Logs dÃ©taillÃ©s avec TensorBoard
- **Mixed precision**: Support AMP pour efficacitÃ©

### ğŸ”§ Configuration (`configs/`)

#### `training_config.yaml` - Configuration Locale
```yaml
# Configuration pour dÃ©veloppement local
data:
  batch_size: 16
  resolution: 256
model:
  latent_dim: 128
training:
  num_epochs: 100
  learning_rate: 1e-4
```

#### `hpc_training_config.yaml` - Configuration HPC
```yaml
# Configuration optimisÃ©e pour HPC
data:
  batch_size: 32        # Batch plus large
  num_workers: 8        # Plus de workers
model:
  latent_dim: 256       # ModÃ¨le plus large
training:
  num_epochs: 200       # Plus d'Ã©poques
  use_amp: true         # Mixed precision
```

### ğŸš€ Scripts HPC

#### Scripts d'Installation
- **`setup_hpc.sh`**: Installation complÃ¨te avec fallbacks
- **`setup_hpc_offline.sh`**: Installation hors ligne
- **`setup_asuka.sh`**: Installation spÃ©cifique Asuka
- **`setup_asuka_custom.sh`**: Installation personnalisÃ©e

#### Scripts de VÃ©rification
- **`check_hpc_environment.sh`**: Diagnostic complet
- **`check_hpc_readiness.sh`**: VÃ©rification prÃ©paration

#### Scripts de Transfert
- **`transfer_to_hpc.sh`**: Transfert vers HPC gÃ©nÃ©rique
- **`transfer_to_asuka.sh`**: Transfert vers Asuka

#### Scripts de Monitoring
- **`monitor_hpc.sh`**: Surveillance des jobs
- **`download_results.sh`**: RÃ©cupÃ©ration des rÃ©sultats

### ğŸ“‹ Jobs SLURM

#### `train_job.slurm` - Job Standard
```bash
#!/bin/bash
#SBATCH --job-name=nlbs-cvae
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=8
#SBATCH --mem=32G
#SBATCH --time=24:00:00
```

#### `train_asuka.slurm` - Job Asuka
```bash
#!/bin/bash
#SBATCH --job-name=nlbs-cvae-asuka
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=12:00:00
```

### ğŸ§ª Tests et DÃ©monstrations

#### `demo.py` - DÃ©monstration ComplÃ¨te
- Chargement des donnÃ©es
- CrÃ©ation du modÃ¨le
- EntraÃ®nement court
- GÃ©nÃ©ration d'Ã©chantillons
- Visualisation des rÃ©sultats

#### `quick_train.py` - EntraÃ®nement Rapide
- Configuration minimale
- EntraÃ®nement accÃ©lÃ©rÃ©
- Test de fonctionnalitÃ©

#### Scripts de Test
- **`test_model.py`**: Test architecture modÃ¨le
- **`test_dataset.py`**: Test chargement donnÃ©es
- **`test_structure.py`**: Test structure projet
- **`test_training.py`**: Test boucle entraÃ®nement

### ğŸ“¦ Gestion des DÃ©pendances

#### `requirements.txt` - Standard
```
torch>=1.12.0
torchvision>=0.13.0
pandas>=1.3.0
pyyaml>=5.4.0
tqdm>=4.62.0
albumentations>=1.1.0
opencv-python>=4.5.0
scipy>=1.7.0
scikit-image>=0.18.0
pydicom>=2.2.0
tensorboard>=2.7.0
matplotlib>=3.4.0
seaborn>=0.11.0
```

#### `requirements_hpc.txt` - HPC OptimisÃ©
- Versions spÃ©cifiques pour HPC
- Support CUDA
- Optimisations performance

### ğŸ“ Structure des RÃ©sultats

```
results/
â”œâ”€â”€ checkpoints/          # Points de sauvegarde
â”‚   â”œâ”€â”€ model_epoch_010.pth
â”‚   â”œâ”€â”€ model_epoch_020.pth
â”‚   â””â”€â”€ best_model.pth
â”œâ”€â”€ logs/                 # Logs d'entraÃ®nement
â”‚   â”œâ”€â”€ tensorboard/
â”‚   â””â”€â”€ training.log
â”œâ”€â”€ galleries/            # Images gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ epoch_010/
â”‚   â”œâ”€â”€ epoch_020/
â”‚   â””â”€â”€ final_samples/
â””â”€â”€ metrics/              # MÃ©triques d'Ã©valuation
    â”œâ”€â”€ fid_scores.json
    â”œâ”€â”€ ssim_scores.json
    â””â”€â”€ evaluation_report.pdf
```

## Flux de Travail

### 1. DÃ©veloppement Local
```bash
# Installation
pip install -r requirements.txt

# Test rapide
python quick_train.py

# DÃ©monstration complÃ¨te
python demo.py
```

### 2. DÃ©ploiement HPC
```bash
# Transfert vers HPC
./transfer_to_hpc.sh

# Installation sur HPC
./setup_hpc.sh

# VÃ©rification
./check_hpc_environment.sh

# Soumission job
sbatch train_job.slurm
```

### 3. Monitoring et RÃ©sultats
```bash
# Surveillance
./monitor_hpc.sh

# TÃ©lÃ©chargement rÃ©sultats
./download_results.sh
```

## CaractÃ©ristiques Techniques

### Optimisations HPC
- **Mixed Precision**: RÃ©duction mÃ©moire GPU
- **Gradient Clipping**: StabilitÃ© d'entraÃ®nement
- **Batch Size Adaptatif**: Selon ressources disponibles
- **Multi-GPU**: Support DataParallel
- **Checkpointing**: Sauvegarde rÃ©guliÃ¨re

### Robustesse
- **Fallback Installation**: MÃ©thodes alternatives
- **Error Handling**: Gestion d'erreurs complÃ¨te
- **Validation**: Tests automatiques
- **Documentation**: Guides dÃ©taillÃ©s

### Performance
- **Efficient Data Loading**: Chargement optimisÃ©
- **Memory Management**: Gestion mÃ©moire efficace
- **Parallel Processing**: Traitement parallÃ¨le
- **GPU Optimization**: Optimisations CUDA

## Utilisation RecommandÃ©e

1. **DÃ©veloppement**: Utiliser configuration locale
2. **Test**: Scripts de test pour validation
3. **Production**: Configuration HPC pour entraÃ®nement complet
4. **Monitoring**: Scripts de surveillance pour suivi
5. **Ã‰valuation**: Scripts d'Ã©valuation pour mÃ©triques

Cette structure modulaire permet un dÃ©veloppement efficace, un dÃ©ploiement robuste sur HPC, et une maintenance facilitÃ©e du projet NLBS-CVAE.