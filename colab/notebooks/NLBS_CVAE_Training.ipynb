{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# NLBS-CVAE: Conditional VAE for Mammography Generation\n",
    "\n",
    "This notebook provides a complete training pipeline for the NLBS-CVAE model on Google Colab.\n",
    "\n",
    "## Features:\n",
    "- üöÄ Optimized for Colab GPU/TPU\n",
    "- üíæ Google Drive integration for data and checkpoints\n",
    "- üìä Real-time monitoring with TensorBoard\n",
    "- üîÑ Automatic session management\n",
    "- üìà Memory optimization for long training sessions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Training will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create necessary directories\n",
    "import os\n",
    "os.makedirs('/content/results', exist_ok=True)\n",
    "os.makedirs('/content/results/checkpoints', exist_ok=True)\n",
    "os.makedirs('/content/results/logs', exist_ok=True)\n",
    "os.makedirs('/content/results/galleries', exist_ok=True)\n",
    "os.makedirs('/content/data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/FructueuxCODJIA/nlbs-cvae.git /content/nlbs-cvae\n",
    "%cd /content/nlbs-cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_requirements"
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r colab/requirements_colab.txt\n",
    "\n",
    "# Install additional packages that might be needed\n",
    "!pip install -q gdown  # For downloading files from Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_setup"
   },
   "source": [
    "## 2. Data Setup\n",
    "\n",
    "Choose one of the following options for data setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_option_1"
   },
   "source": [
    "### Option 1: Use Demo/Synthetic Data (Recommended for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_demo_data"
   },
   "outputs": [],
   "source": [
    "# Create synthetic demo data for testing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "from pydicom.dataset import Dataset, FileDataset\n",
    "from pydicom.uid import ExplicitVRLittleEndian\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def create_synthetic_mammogram(width=512, height=512):\n",
    "    \"\"\"Create a synthetic mammogram-like image\"\"\"\n",
    "    # Create base tissue pattern\n",
    "    x, y = np.meshgrid(np.linspace(0, 1, width), np.linspace(0, 1, height))\n",
    "    \n",
    "    # Simulate breast tissue with varying density\n",
    "    tissue = np.exp(-((x-0.5)**2 + (y-0.5)**2) * 3)\n",
    "    \n",
    "    # Add some texture\n",
    "    noise = np.random.normal(0, 0.1, (height, width))\n",
    "    texture = np.sin(x * 20) * np.sin(y * 20) * 0.1\n",
    "    \n",
    "    # Combine and normalize\n",
    "    image = tissue + texture + noise\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    # Convert to uint16 (typical for mammograms)\n",
    "    image = (image * 65535).astype(np.uint16)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_synthetic_dicom(image_array, filename):\n",
    "    \"\"\"Create a synthetic DICOM file\"\"\"\n",
    "    # Create file meta information\n",
    "    file_meta = Dataset()\n",
    "    file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.1.2'  # Digital Mammography X-Ray Image\n",
    "    file_meta.MediaStorageSOPInstanceUID = '1.2.3.4.5.6.7.8.9.10'\n",
    "    file_meta.ImplementationClassUID = '1.2.3.4.5.6.7.8.9.10'\n",
    "    file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\n",
    "    \n",
    "    # Create the main dataset\n",
    "    ds = FileDataset(filename, {}, file_meta=file_meta, preamble=b\"\\0\" * 128)\n",
    "    \n",
    "    # Add required DICOM tags\n",
    "    ds.PatientName = \"Demo^Patient\"\n",
    "    ds.PatientID = \"DEMO001\"\n",
    "    ds.Modality = \"MG\"\n",
    "    ds.StudyInstanceUID = \"1.2.3.4.5.6.7.8.9.10.11\"\n",
    "    ds.SeriesInstanceUID = \"1.2.3.4.5.6.7.8.9.10.11.12\"\n",
    "    ds.SOPInstanceUID = \"1.2.3.4.5.6.7.8.9.10.11.12.13\"\n",
    "    ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.1.2'\n",
    "    \n",
    "    # Image-specific tags\n",
    "    ds.SamplesPerPixel = 1\n",
    "    ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "    ds.Rows, ds.Columns = image_array.shape\n",
    "    ds.BitsAllocated = 16\n",
    "    ds.BitsStored = 16\n",
    "    ds.HighBit = 15\n",
    "    ds.PixelRepresentation = 0\n",
    "    ds.PixelData = image_array.tobytes()\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Create demo dataset\n",
    "print(\"Creating synthetic demo dataset...\")\n",
    "\n",
    "# Create directory structure\n",
    "demo_dir = Path('/content/data/demo')\n",
    "demo_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate synthetic data\n",
    "metadata_rows = []\n",
    "views = ['CC', 'MLO']\n",
    "lateralities = ['L', 'R']\n",
    "ages = [45, 52, 58, 63, 67]\n",
    "\n",
    "for patient_id in range(1, 21):  # 20 patients\n",
    "    age = np.random.choice(ages)\n",
    "    cancer = np.random.choice([0, 1], p=[0.7, 0.3])  # 30% cancer cases\n",
    "    \n",
    "    for laterality in lateralities:\n",
    "        for view in views:\n",
    "            # Create synthetic image\n",
    "            image = create_synthetic_mammogram()\n",
    "            \n",
    "            # Create filename\n",
    "            filename = f\"patient_{patient_id:03d}_{laterality}_{view}.dcm\"\n",
    "            filepath = demo_dir / filename\n",
    "            \n",
    "            # Create and save DICOM\n",
    "            ds = create_synthetic_dicom(image, str(filepath))\n",
    "            ds.save_as(filepath)\n",
    "            \n",
    "            # Add to metadata\n",
    "            metadata_rows.append({\n",
    "                'File Path': f'demo/{filename}',\n",
    "                'Image Laterality': laterality,\n",
    "                'View Position': view,\n",
    "                'Age': age,\n",
    "                'Cancer': cancer,\n",
    "                'False Positive': np.random.choice([0, 1], p=[0.9, 0.1])\n",
    "            })\n",
    "\n",
    "# Create metadata CSV\n",
    "metadata_df = pd.DataFrame(metadata_rows)\n",
    "metadata_df.to_csv('/content/data/metadata.csv', index=False)\n",
    "\n",
    "print(f\"Created {len(metadata_rows)} synthetic mammogram files\")\n",
    "print(f\"Metadata saved to /content/data/metadata.csv\")\n",
    "print(f\"Images saved to {demo_dir}\")\n",
    "\n",
    "# Update config paths\n",
    "data_config = {\n",
    "    'csv_path': '/content/data/metadata.csv',\n",
    "    'image_dir': '/content/data'\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Demo data setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_option_2"
   },
   "source": [
    "### Option 2: Upload Your Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you want to upload your own data\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import shutil\n",
    "\n",
    "# print(\"Please upload your data as a ZIP file containing:\")\n",
    "# print(\"1. metadata.csv - with columns: File Path, Image Laterality, View Position, Age, Cancer, False Positive\")\n",
    "# print(\"2. images/ folder - containing your DICOM files\")\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # Extract uploaded files\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('/content/data')\n",
    "#         print(f\"Extracted {filename} to /content/data\")\n",
    "\n",
    "# # Update config paths\n",
    "# data_config = {\n",
    "#     'csv_path': '/content/data/metadata.csv',\n",
    "#     'image_dir': '/content/data'\n",
    "# }\n",
    "\n",
    "# print(\"\\n‚úÖ Data upload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_option_3"
   },
   "source": [
    "### Option 3: Load from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_from_drive"
   },
   "outputs": [],
   "source": [
    "# Uncomment and modify this cell if your data is in Google Drive\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# # Specify your Google Drive data path\n",
    "# drive_data_path = '/content/drive/MyDrive/NLBS_Data'  # Modify this path\n",
    "\n",
    "# if os.path.exists(drive_data_path):\n",
    "#     # Copy metadata\n",
    "#     if os.path.exists(f'{drive_data_path}/metadata.csv'):\n",
    "#         shutil.copy(f'{drive_data_path}/metadata.csv', '/content/data/metadata.csv')\n",
    "#         print(\"Metadata copied from Drive\")\n",
    "#     \n",
    "#     # Create symlink to images (faster than copying)\n",
    "#     if os.path.exists(f'{drive_data_path}/images'):\n",
    "#         if os.path.exists('/content/data/images'):\n",
    "#             os.remove('/content/data/images')\n",
    "#         os.symlink(f'{drive_data_path}/images', '/content/data/images')\n",
    "#         print(\"Images linked from Drive\")\n",
    "#     \n",
    "#     # Update config paths\n",
    "#     data_config = {\n",
    "#         'csv_path': '/content/data/metadata.csv',\n",
    "#         'image_dir': '/content/data'\n",
    "#     }\n",
    "#     \n",
    "#     print(\"\\n‚úÖ Data loaded from Google Drive!\")\n",
    "# else:\n",
    "#     print(f\"‚ùå Data path not found: {drive_data_path}\")\n",
    "#     print(\"Please check your Google Drive path and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_option_4"
   },
   "source": [
    "### Option 4: NLBSP Dataset (Real Mammography Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_nlbsp_data"
   },
   "outputs": [],
   "source": [
    "# Setup for real NLBSP mammography dataset\n",
    "# Uncomment and run this cell if you have the NLBSP dataset\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/nlbs-cvae')\n",
    "# from colab.utils.nlbsp_data_prep import setup_nlbsp_for_training\n",
    "\n",
    "# # Choose data source: \"upload\" or \"drive\"\n",
    "# data_source = \"upload\"  # Change to \"drive\" if data is in Google Drive\n",
    "\n",
    "# print(\"üîÑ Setting up NLBSP dataset...\")\n",
    "# csv_path, image_dir = setup_nlbsp_for_training(data_source=data_source)\n",
    "\n",
    "# if csv_path and image_dir:\n",
    "#     # Use the real data configuration\n",
    "#     import yaml\n",
    "#     with open('/content/nlbs-cvae/colab/configs/colab_real_data_config.yaml', 'r') as f:\n",
    "#         config = yaml.safe_load(f)\n",
    "#     \n",
    "#     # Update paths\n",
    "#     config['data']['csv_path'] = csv_path\n",
    "#     config['data']['image_dir'] = image_dir\n",
    "#     \n",
    "#     data_config = {\n",
    "#         'csv_path': csv_path,\n",
    "#         'image_dir': image_dir\n",
    "#     }\n",
    "#     \n",
    "#     print(f\"‚úÖ NLBSP dataset ready!\")\n",
    "#     print(f\"CSV: {csv_path}\")\n",
    "#     print(f\"Images: {image_dir}\")\n",
    "#     print(\"\\nüìä This configuration is optimized for real mammography data\")\n",
    "# else:\n",
    "#     print(\"‚ùå Failed to setup NLBSP data\")\n",
    "#     print(\"Please check your data files and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_training"
   },
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_modules"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('/content/nlbs-cvae')\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Import project modules\n",
    "from models import ConditionalVAE\n",
    "from models.losses import VAELoss\n",
    "from data import MammographyDataset\n",
    "from utils.training_utils import (\n",
    "    setup_logging, \n",
    "    save_checkpoint, \n",
    "    load_checkpoint,\n",
    "    create_optimizer,\n",
    "    create_scheduler,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_config"
   },
   "outputs": [],
   "source": [
    "# Load and modify configuration\n",
    "with open('/content/nlbs-cvae/colab/configs/colab_training_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update data paths if using custom data\n",
    "if 'data_config' in locals():\n",
    "    config['data'].update(data_config)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config['hardware']['device'] = str(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Data path: {config['data']['csv_path']}\")\n",
    "print(f\"Image dir: {config['data']['image_dir']}\")\n",
    "\n",
    "# Set random seed\n",
    "set_seed(config['project']['seed'])\n",
    "\n",
    "print(\"‚úÖ Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset"
   },
   "outputs": [],
   "source": [
    "# Create dataset and data loaders\n",
    "print(\"Creating dataset...\")\n",
    "\n",
    "# Load metadata\n",
    "metadata_df = pd.read_csv(config['data']['csv_path'])\n",
    "print(f\"Loaded {len(metadata_df)} samples\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = MammographyDataset(\n",
    "    csv_path=config['data']['csv_path'],\n",
    "    image_dir=config['data']['image_dir'],\n",
    "    resolution=config['data']['resolution'],\n",
    "    augment=True,\n",
    "    patch_stride=config['data']['patch_stride'],\n",
    "    min_foreground_frac=config['data']['min_foreground_frac']\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} patches\")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(config['data']['train_split'] * len(dataset))\n",
    "val_size = int(config['data']['val_split'] * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['data']['num_workers'],\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['data']['num_workers'],\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(\"‚úÖ Data loaders created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"Creating model...\")\n",
    "\n",
    "model = ConditionalVAE(\n",
    "    in_channels=config['data']['channels'],\n",
    "    image_size=config['data']['resolution'],\n",
    "    latent_dim=config['model']['latent_dim'],\n",
    "    condition_embed_dim=config['model']['condition_embed_dim'],\n",
    "    encoder_channels=config['model']['encoder']['channels'],\n",
    "    decoder_channels=config['model']['decoder']['channels']\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model created with {total_params:,} total parameters\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Create loss function\n",
    "criterion = VAELoss(\n",
    "    reconstruction_weight=config['training']['loss']['reconstruction_weight'],\n",
    "    kl_weight=config['training']['loss']['kl_weight'],\n",
    "    edge_weight=config['training']['loss']['edge_weight']\n",
    ")\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = create_optimizer(model, config['training'])\n",
    "\n",
    "# Create scheduler\n",
    "scheduler = create_scheduler(optimizer, config['training'], len(train_loader))\n",
    "\n",
    "print(\"‚úÖ Model, loss, optimizer, and scheduler created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_logging"
   },
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "writer = SummaryWriter(config['logging']['log_dir'])\n",
    "\n",
    "# Setup logging to file\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('/content/results/training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Logging setup complete!\")\n",
    "\n",
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "print(\"\\nüìä TensorBoard will be available at the end of this cell\")\n",
    "%tensorboard --logdir /content/results/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_loop"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Training variables\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "global_step = 0\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler() if config['training']['mixed_precision'] == 'fp16' else None\n",
    "\n",
    "for epoch in range(config['training']['num_epochs']):\n",
    "    print(f\"\\n=== Epoch {epoch+1}/{config['training']['num_epochs']} ===\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_recon_loss = 0.0\n",
    "    train_kl_loss = 0.0\n",
    "    \n",
    "    # KL annealing\n",
    "    kl_weight = min(1.0, epoch / config['training']['loss']['kl_anneal_epochs'])\n",
    "    criterion.kl_weight = kl_weight\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        images = batch['image'].to(device)\n",
    "        conditions = {k: v.to(device) for k, v in batch['conditions'].items()}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images, conditions)\n",
    "                loss_dict = criterion(outputs, images)\n",
    "                loss = loss_dict['total_loss']\n",
    "            \n",
    "            # Backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if config['training']['gradient_clip'] > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['training']['gradient_clip'])\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images, conditions)\n",
    "            loss_dict = criterion(outputs, images)\n",
    "            loss = loss_dict['total_loss']\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if config['training']['gradient_clip'] > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['training']['gradient_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += loss.item()\n",
    "        train_recon_loss += loss_dict['reconstruction_loss'].item()\n",
    "        train_kl_loss += loss_dict['kl_loss'].item()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        if global_step % config['logging']['log_every_n_steps'] == 0:\n",
    "            writer.add_scalar('Train/Loss', loss.item(), global_step)\n",
    "            writer.add_scalar('Train/Reconstruction_Loss', loss_dict['reconstruction_loss'].item(), global_step)\n",
    "            writer.add_scalar('Train/KL_Loss', loss_dict['kl_loss'].item(), global_step)\n",
    "            writer.add_scalar('Train/KL_Weight', kl_weight, global_step)\n",
    "            writer.add_scalar('Train/Learning_Rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "        \n",
    "        global_step += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Recon': f'{loss_dict[\"reconstruction_loss\"].item():.4f}',\n",
    "            'KL': f'{loss_dict[\"kl_loss\"].item():.4f}',\n",
    "            'KL_w': f'{kl_weight:.3f}'\n",
    "        })\n",
    "        \n",
    "        # Memory cleanup\n",
    "        if batch_idx % 50 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate average training losses\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_recon = train_recon_loss / len(train_loader)\n",
    "    avg_train_kl = train_kl_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} (Recon: {avg_train_recon:.4f}, KL: {avg_train_kl:.4f})\")\n",
    "    \n",
    "    # Validation phase\n",
    "    if (epoch + 1) % config['evaluation']['val_every_n_epochs'] == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_recon_loss = 0.0\n",
    "        val_kl_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images = batch['image'].to(device)\n",
    "                conditions = {k: v.to(device) for k, v in batch['conditions'].items()}\n",
    "                \n",
    "                outputs = model(images, conditions)\n",
    "                loss_dict = criterion(outputs, images)\n",
    "                \n",
    "                val_loss += loss_dict['total_loss'].item()\n",
    "                val_recon_loss += loss_dict['reconstruction_loss'].item()\n",
    "                val_kl_loss += loss_dict['kl_loss'].item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_recon = val_recon_loss / len(val_loader)\n",
    "        avg_val_kl = val_kl_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Val Loss: {avg_val_loss:.4f} (Recon: {avg_val_recon:.4f}, KL: {avg_val_kl:.4f})\")\n",
    "        \n",
    "        # Log validation metrics\n",
    "        writer.add_scalar('Val/Loss', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Val/Reconstruction_Loss', avg_val_recon, epoch)\n",
    "        writer.add_scalar('Val/KL_Loss', avg_val_kl, epoch)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler, epoch, avg_val_loss,\n",
    "                '/content/results/checkpoints/best_model.pth'\n",
    "            )\n",
    "            print(\"üíæ Best model saved!\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= config['training']['early_stopping_patience']:\n",
    "            print(f\"Early stopping triggered after {patience_counter} epochs without improvement\")\n",
    "            break\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % config['training']['save_every_n_epochs'] == 0:\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler, epoch, avg_train_loss,\n",
    "            f'/content/results/checkpoints/checkpoint_epoch_{epoch+1}.pth'\n",
    "        )\n",
    "        print(f\"üíæ Checkpoint saved for epoch {epoch+1}\")\n",
    "    \n",
    "    # Generate sample images\n",
    "    if (epoch + 1) % config['logging']['save_images_every_n_epochs'] == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get a batch for reconstruction\n",
    "            sample_batch = next(iter(val_loader))\n",
    "            sample_images = sample_batch['image'][:4].to(device)\n",
    "            sample_conditions = {k: v[:4].to(device) for k, v in sample_batch['conditions'].items()}\n",
    "            \n",
    "            # Reconstruct\n",
    "            outputs = model(sample_images, sample_conditions)\n",
    "            reconstructions = outputs['reconstruction']\n",
    "            \n",
    "            # Generate new samples\n",
    "            generated = model.sample(sample_conditions, batch_size=4)\n",
    "            \n",
    "            # Create comparison grid\n",
    "            fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "            \n",
    "            for i in range(4):\n",
    "                # Original\n",
    "                axes[0, i].imshow(sample_images[i, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[0, i].set_title(f'Original {i+1}')\n",
    "                axes[0, i].axis('off')\n",
    "                \n",
    "                # Reconstruction\n",
    "                axes[1, i].imshow(reconstructions[i, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[1, i].set_title(f'Reconstruction {i+1}')\n",
    "                axes[1, i].axis('off')\n",
    "                \n",
    "                # Generated\n",
    "                axes[2, i].imshow(generated[i, 0].cpu().numpy(), cmap='gray')\n",
    "                axes[2, i].set_title(f'Generated {i+1}')\n",
    "                axes[2, i].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'/content/results/galleries/epoch_{epoch+1}_samples.png', dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Log to TensorBoard\n",
    "            writer.add_figure('Samples/Comparison', fig, epoch)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if (epoch + 1) % config['colab']['clear_cache_every_n_epochs'] == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"üßπ Memory cache cleared\")\n",
    "\n",
    "print(\"\\nüéâ Training completed!\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 4. Model Evaluation and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_best_model"
   },
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "checkpoint_path = '/content/results/checkpoints/best_model.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"Best validation loss: {checkpoint['loss']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No checkpoint found, using current model state\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_samples"
   },
   "outputs": [],
   "source": [
    "# Generate diverse samples\n",
    "print(\"Generating diverse mammogram samples...\")\n",
    "\n",
    "# Define different conditions to test\n",
    "test_conditions = [\n",
    "    {'view': 0, 'laterality': 0, 'age_bin': 1, 'cancer': 0, 'false_positive': 0},  # CC, Left, Young, No cancer\n",
    "    {'view': 1, 'laterality': 1, 'age_bin': 2, 'cancer': 1, 'false_positive': 0},  # MLO, Right, Middle, Cancer\n",
    "    {'view': 0, 'laterality': 1, 'age_bin': 3, 'cancer': 0, 'false_positive': 1},  # CC, Right, Old, False positive\n",
    "    {'view': 1, 'laterality': 0, 'age_bin': 0, 'cancer': 1, 'false_positive': 0},  # MLO, Left, Very young, Cancer\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, condition_dict in enumerate(test_conditions):\n",
    "        # Convert to tensor format\n",
    "        conditions = {}\n",
    "        for key, value in condition_dict.items():\n",
    "            conditions[key] = torch.tensor([value], device=device)\n",
    "        \n",
    "        # Generate 2 samples for each condition\n",
    "        generated = model.sample(conditions, batch_size=2)\n",
    "        \n",
    "        for j in range(2):\n",
    "            axes[j, i].imshow(generated[j, 0].cpu().numpy(), cmap='gray')\n",
    "            \n",
    "            # Create title with condition info\n",
    "            view_name = 'CC' if condition_dict['view'] == 0 else 'MLO'\n",
    "            lat_name = 'Left' if condition_dict['laterality'] == 0 else 'Right'\n",
    "            cancer_status = 'Cancer' if condition_dict['cancer'] == 1 else 'Normal'\n",
    "            \n",
    "            title = f'{view_name}, {lat_name}\\n{cancer_status}'\n",
    "            axes[j, i].set_title(title, fontsize=10)\n",
    "            axes[j, i].axis('off')\n",
    "\n",
    "plt.suptitle('Generated Mammograms with Different Conditions', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/results/galleries/diverse_generations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Diverse samples generated and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "latent_interpolation"
   },
   "outputs": [],
   "source": [
    "# Latent space interpolation\n",
    "print(\"Performing latent space interpolation...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get two random samples from validation set\n",
    "    sample_batch = next(iter(val_loader))\n",
    "    img1, img2 = sample_batch['image'][:2].to(device)\n",
    "    cond1 = {k: v[:1].to(device) for k, v in sample_batch['conditions'].items()}\n",
    "    cond2 = {k: v[1:2].to(device) for k, v in sample_batch['conditions'].items()}\n",
    "    \n",
    "    # Encode to latent space\n",
    "    outputs1 = model.encode(img1.unsqueeze(0), cond1)\n",
    "    outputs2 = model.encode(img2.unsqueeze(0), cond2)\n",
    "    \n",
    "    z1 = outputs1['z']\n",
    "    z2 = outputs2['z']\n",
    "    \n",
    "    # Interpolate between latent codes\n",
    "    n_steps = 8\n",
    "    alphas = torch.linspace(0, 1, n_steps, device=device)\n",
    "    \n",
    "    interpolated_images = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        # Interpolate latent codes\n",
    "        z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "        \n",
    "        # Use first condition for consistency\n",
    "        decoded = model.decode(z_interp, cond1)\n",
    "        interpolated_images.append(decoded['reconstruction'])\n",
    "    \n",
    "    # Plot interpolation\n",
    "    fig, axes = plt.subplots(1, n_steps, figsize=(16, 2))\n",
    "    \n",
    "    for i, img in enumerate(interpolated_images):\n",
    "        axes[i].imshow(img[0, 0].cpu().numpy(), cmap='gray')\n",
    "        axes[i].set_title(f'Œ±={alphas[i]:.2f}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Latent Space Interpolation', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/results/galleries/latent_interpolation.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Latent interpolation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results"
   },
   "source": [
    "## 5. Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "backup_to_drive"
   },
   "outputs": [],
   "source": [
    "# Backup results to Google Drive\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped backup folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = f'/content/drive/MyDrive/NLBS_CVAE_Results_{timestamp}'\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Copy results\n",
    "print(\"Backing up results to Google Drive...\")\n",
    "\n",
    "# Copy checkpoints\n",
    "if os.path.exists('/content/results/checkpoints'):\n",
    "    shutil.copytree('/content/results/checkpoints', f'{backup_dir}/checkpoints')\n",
    "    print(\"‚úÖ Checkpoints backed up\")\n",
    "\n",
    "# Copy galleries\n",
    "if os.path.exists('/content/results/galleries'):\n",
    "    shutil.copytree('/content/results/galleries', f'{backup_dir}/galleries')\n",
    "    print(\"‚úÖ Generated images backed up\")\n",
    "\n",
    "# Copy logs\n",
    "if os.path.exists('/content/results/logs'):\n",
    "    shutil.copytree('/content/results/logs', f'{backup_dir}/logs')\n",
    "    print(\"‚úÖ Training logs backed up\")\n",
    "\n",
    "# Copy training log\n",
    "if os.path.exists('/content/results/training.log'):\n",
    "    shutil.copy('/content/results/training.log', f'{backup_dir}/training.log')\n",
    "    print(\"‚úÖ Training log backed up\")\n",
    "\n",
    "# Save configuration\n",
    "with open(f'{backup_dir}/config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "print(\"‚úÖ Configuration saved\")\n",
    "\n",
    "print(f\"\\nüéâ All results backed up to: {backup_dir}\")\n",
    "print(\"\\nüìã Summary:\")\n",
    "print(f\"- Training completed with {config['training']['num_epochs']} epochs\")\n",
    "print(f\"- Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"- Model parameters: {trainable_params:,}\")\n",
    "print(f\"- Results saved to Google Drive: {backup_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "### üéØ What you can do now:\n",
    "\n",
    "1. **Experiment with different configurations**:\n",
    "   - Modify `colab_training_config.yaml` for different architectures\n",
    "   - Try different loss weights and training parameters\n",
    "\n",
    "2. **Scale up with real data**:\n",
    "   - Upload your mammography dataset to Google Drive\n",
    "   - Modify the data loading section to use your real data\n",
    "   - Increase model size and training epochs\n",
    "\n",
    "3. **Advanced features**:\n",
    "   - Enable W&B logging for better experiment tracking\n",
    "   - Implement additional evaluation metrics (FID, LPIPS)\n",
    "   - Add more sophisticated data augmentation\n",
    "\n",
    "4. **Model deployment**:\n",
    "   - Export trained model for inference\n",
    "   - Create a simple web interface for generation\n",
    "   - Integrate with medical imaging workflows\n",
    "\n",
    "### üìö Resources:\n",
    "- [Original repository](https://github.com/FructueuxCODJIA/nlbs-cvae)\n",
    "- [Google Colab documentation](https://colab.research.google.com/)\n",
    "- [PyTorch documentation](https://pytorch.org/docs/)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}